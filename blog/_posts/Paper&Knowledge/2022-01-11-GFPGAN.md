---
title: "[CVPR2021]Towards Real-World Blind Face Restoration with Generative Facial Prior"
excerpt: "[CVPR2021]Towards Real-World Blind Face Restoration with Generative Facial Prior"
categories:
  - Paper & Knowledge
  
tags:
  - GAN
 
published: True
toc: true
toc_sticky: true
toc_label: "On this page"
use_math: true
    
last_modified_at: 2022-01-11T15:04:00-05:00
---
WDC2022의 첫번째 후처리 방법으로 Face Restoration을 사용하였다. 이 때 적용한 논문. Deepfake Evading을 위한 Face Restoration의 베이스로 삼을 수 있을 것 같다.

# Abstract & Introduction
지금까지 face restoration분야에서 low-quality를 개선시키기 위해 사용한 정보는 geometry와 reference prior 2가지가 있었다. geometry prior는 얼굴의 랜드마크나 heatmap등의 얼굴의 특징을 
사전 정보로 하여 학습을 진행하는 것이다. 하지만 이는 손상이 심한 low-quality에서는 잘못된 정보가 추출되거나, 심지어는 더 이상 얼굴로써 인식하기 힘들기 때문에 정보를 얻을 수 없다는 한계가 있다. 또한 이러한 정보는 
전체 이미지를 자세히 볼 수 없다. 예를 들어 랜드마크를 활용한다 할 때, 랜드마크는 눈, 코, 입 등의 spatial한 정보를 포함할 수는 있지만, 눈꺼풀, 동공, 주름과 같은 자세한 texture 정보는 담을 수 없다. 
reference prior는 high quality guided face, 즉 손상 되기 전의 reference 얼굴을 활용하여 학습을 진행하지만, high-resolution reference 이미지를 얻기 힘든 경우에 제한이 될 수 있고, 
이 논문에서는 StyleGAN2과 같은 pretrained face generative 모델을 활용하여 사전 정보를 추출한다. 이는 latent상에서 low-quality 이미지들을 high-quality 이미지들과 매칭하기 때문에
전체적인 이미지를 볼 수 있고, 사람이 인식하지 못하는 섬세한 feature까지 커버할 수 있다고 한다. 

# Related Work
### Image Restoration
Image restoration은 super-resolution, denoising, deblurring, compression removal들을 포함한다. 이 논문에서는 super resolution을 포함하는 image restoration을 다루기 때문에 low-quality이미지를 
만들기 위해 위의 4가지 기법을 모두 섞어 만들었다. 

### Face Restoration
Face Restroation을 하기 위해 크게 세 가지의 prior를 이용한다.
1. Facial Geometry Prior 
- facial landmark, face parsing maps, facial component heatmap를 사전 정보로 이용한다. 하지만 <br/>
- low-quality 이미지의 사전정보 또한 요하므로 low-quality 이미지에서 정보를 뽑을 수 없으면 사용할 수 없다.
- geometry에만 집중하므로 다른 복원할 디테일한 부분을 고려하지 못할 수 있다.
 
2. Reference Prior
- Facial component dictionary, 즉, 얼굴의 눈, 코, 입 등을 부분적으로 크롭해서 생성된 high qulity와 비교함.
- 이것도 그 부분은 고려 할 수 있으나 전체적인 이미지를 볼 떄 취약할 수 있다.
- 생성 이미지에서 dictionary를 완성하지 못 할수도 있다.

3. Generative Prior
- GAN 등의 facial generative model을 사용하여 어떤 얼굴 이미지의 스타일이나 특징을 담은 벡터를 뽑아 활용한다.
- 기존의 연구애서는 추출된 벡터의 차원이 낮기 떄문에 fidelity가 떨어졌다고 주장한다.

![](/assets/images/2022-01-13-GFP_GAN/1.JPG)
# Method
메소드 파트는 크게 
1. 모델 - degradation removal module, pretrained face GAN
2. 모듈 - channle-split spatial feature transform (CS-SFT)
3. 손실 함수 - restoration loss, adversarial loss, facial component loss, identity preserving guidance loss
로 나눌 수 있다.

### Degradation Removal Module
U-Net 기반의 오토 인코더이다. 인코더 7개, 디코더 7개로 이루어져 입력 해상도 512에 대해서 7번 다운샘플링 되어 4까지 된다. 가장 깊은 레이어에서 $F_{latent}$를 뽑고, 각 디코더에서 $F_{spatial}$을 뽑았다. 나중에 
ablation에서 보여주지만, $F_{spatial}$이 중요한데, 이 feature vector가 공간적인 정보를 담고 있다. 

### Pretrained Face GAN
훈련된 facial GAN으로는 StyleGAN2를 사용하였다. U-Net에서 나온 $F_{latent}$를 사용하기 전에 먼저 MLP레이어에 입력으로 하여 정제된 벡터 $\mathcal{W}$를 얻는다. 그 다음 stylegan2의 레이어를 통과시켜 $F_{GAN}$을 뽑는다.
$F_{spatial}$은 MLP를 거치지 않고 그대로 들어가는데 CS-SFT레이어를 활용한다.

### Channel-Split Spatial Feature Transform
그림을 보면 쉽게 알 수 있는데 순서를 정리하면 아래와 같다.
1. $F_{GAN}$을 두개로 나눈다. 
2. $F_{spatial}$을 conv 레이어를 통과시켜 두개의 파라미터 $\alpha$, $\beta$를 뽑는다.
3. 두개로 나눈 $F_{GAN}$의 두번째에 $\alpha$, $\beta$를 곱하고 더한 다음, 나머지 하나와 concatenate한다.
식은 아래와 같다.
![](/assets/images/2022-01-13-GFP_GAN/2.JPG) 

### Restoration Loss
전체적인 구조를 잡는 손실함수이다. L1-Loss와 VGGLoss를 활용하여 만들었다. 식은 아래와 같다. 
![](/assets/images/2022-01-13-GFP_GAN/3.JPG)

### Adversarial Loss
GAN의 적대적 손실함수로써 sigmoid 대신 softplus를 사용하였다. 왜 사용했는지는 softplus를 사용한 논문을 더 찾아봐야 할 것 같다.
![](/assets/images/2022-01-13-GFP_GAN/4.JPG)

### Facial Component Loss
이전에 소개한 3가지 Prior중 2번째 prior의 reference prior에 속하는 손실함수이다. 얼굴에서 중요한 부분을 차지하는 눈, 코, 입등을 크롭하여 집중적으로 가짜인지 진짜인지 판별하는 손실함수이다. 여러개의 Discriminator를 두고 
각 얼굴 component에 대한 이미지를 분류한다.
![](/assets/images/2022-01-13-GFP_GAN/5.JPG)

### Identity Preserving Guidance Loss
마지막으로 low-quality의 이미지로부터 생성된 high-quality이미지의 identity를 맞춰주기 위한 손실 함수이다. Arcface를 활용하여 생성된 이미지와 진짜 이미지의 identity 거리를 최소화 한다.
![](/assets/images/2022-01-13-GFP_GAN/6.JPG)

# Experiments
### Datasets
훈련 데이터로는 FFHQ를 사용하였고, 해상도는 512x512를 사용하였다. low-quality 이미지를 만들기 위해 blurring, downsample, noise, JPEG compression을 랜덤하게 적용하였는데, 식은 아래와 같다.
![](/assets/images/2022-01-13-GFP_GAN/7.JPG)
scale factor를 랜덤으로 사용하였다는 것에 주목하자.<br/>
테스트 데이터셋으로는 CelebA, LFW, CelebChild, Webphoto를 사용하였다.

### Metrics
GAN에서 항상 화제가 되는 지표 정하기이다. 이 논문에서는 기존의 perceptual metric, pixel-wise metric, identity distance를 사용하였다.
1. Perceptual Metric - FID, NIQE, LPIPS (LPIPS의 자세한 설명은 [링크](https://github.com/richzhang/PerceptualSimilarity/blob/31bc1271ae6f13b7e281b9959ac24a5e8f2ed522/lpips/lpips.py),
NIQE는 [링크](https://bskyvision.com/796)를 참조하자)
2. Pixel-wise Metric - PSNR, SSIM
3. Identity Distance - Arcface를 통과시켜 두 벡터간의 각도를 계산.

### Blurring, Noise, JPEG Compression
우선 blurring, noise, JPEG 압축만을 적용한 동일한 해상도의 low-quality 이미지를 변환하였다.
![](/assets/images/2022-01-13-GFP_GAN/8.JPG)
![](/assets/images/2022-01-13-GFP_GAN/9.JPG)
위의 이미지와 결과표에서 나와있듯이, Perceptual metric과 Identity distance에서는 좋은 성능을 보이지만 pixel-wise metric에서는 좋지 못하다.
하지만 pixel-wise metric에서 가장 좋은 성능을 보이는 DeblurGANv2에서는 그림과 같이 속눈썹과 같은 디테일한 부분을 잘 표현하지 못한다.
또한 주목해야 할 점은 identity distance (표에서는 Deg.로 표시)가 중요한 지표라는 것인데, PULSE 모델은 상당히 높은 identity distance를 갖고 있다.
따라서 이미지에서 알 수 있듯이 GT 이미지와 PULSE 모델이 생성한 이미지에서는 다른 사람이 생성된 것을 볼 수 있다.

### Super Resolution 
다음으로는 위의 3가지 변환 과정을 제외하고 super resolution task에서의 GFP-GAN성능을 비교한다.
![](/assets/images/2022-01-13-GFP_GAN/10.JPG)
여기서도 또한 pixel-wise metric은 좋지 않지만, 나머지 지표에서는 좋은 성능을 보인다. 

# Ablation Study
![](/assets/images/2022-01-13-GFP_GAN/11.JPG)
표에 자세히 나와있듯, <br/>
Config. a) CS-SFT자체를 없앰<br/>
Config. b) CS만 없앰<br/>
Config. c) GFP를 없앰<br/>
Config. d) Restoration loss를 없앰<br/>
가장 많은 변화를 준것은 config. a)이다. 나머지들도 모두 성능 향상을 가져다 준다는 것에 의의를 둠.

