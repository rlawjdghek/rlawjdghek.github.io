---
title:  "[ICCV2021]Self-Knowledge Distillation with Progressive Refinement of Targets"
excerpt: "[ICCV2021]Self-Knowledge Distillation with Progressive Refinement of Targets"
categories:
  - Paper & Knowledge
  
tags:
  - KD
 
published: True
toc: true
toc_sticky: true
toc_label: "On this page"
use_math: true
    
last_modified_at: 2021-11-17T15:04:00-05:00
---

방법론은 간단하지만 그만큼 적용하기 쉽다는 뜻이고 teacher가 없는 self-distillation이므로 학습 메커니즘을 제공할 수 있다. 하지만 성능이 증가하는 만큼 추가 VRAM이나 RAM을 요구한다.
* calibration: 모델이 잘못된 예측을 했을 떄의 confidence 정도. 덜 calibration이 된 경우에는 output중 높은 confidence을 갖고 있으나 정답이라고 예측한 것이 더 많다는 것이다. 

# Abstract & Introduction
teacher를 사용한 일반적인 KD와는 달리 self-KD에서 성능이 증가하는 것은 regularization을 얼마나 잘 하느냐에 달려있다고 주장한다. 현재 뉴럴 네트워크들은 모델의 크기가 커질수록 성능이 잘
나온다고 알려져 있지만, 이것은 특정 metric (정확도, recall 등등)에서만 적용되는 말이다. ECE 등의 confidence 기반의 metric에서는 오히려 작은 모델들이 큰 모델보다 더 좋은 성능을 낼 수 
있다. 예를 들어, 의학 분야에서 사용되는 딥러닝 모델은 confidence 스코어에 따라 환자를 진단하기 때문에 잘못된 예측을 하더라도 confidence가 낮으면 재검토 가능성이 열릴 수 있다.
이 논문은 accuracy 등의 고전적인 지표의 성능을 증가시키는 것 뿐만 아니라 ECE 등의 지표 성능도 보여준다. 실험 결과를 보면 정확도보다 ECE 성능지표가 더 높은 것을 볼 수 있다. 따라서 이런 내용을 
강조한듯.

# Methods 
정말 쉽다. 논문에서는 progressive self-knowledge distillation이라는 것을 소개한다. 과거의 모델의 예측값을 저장해 두고 현재 모델의 손실함수에 적용하는 것이 전부이다.
구현 할 때 과거의 모델들을 사용하는 방법은 2가지가 있다.
1. 과거의 모델을 VRAM에 저장시킨 뒤, 현재 모델을 훈련할 때 같이 forward 하는법 -> 시간과 VRAM이 모두 소요
2. 과거의 모델의 예측값을 RAM에 저장한 뒤 손실 함수 계산에 사용 하는법 -> RAM 소요, 시간은 적게소모
task에 따라 다르게 작동할 수 있다. RAM에 들어갈 수만 있다면 2번 방법이 좋겠지만 (CIFAR100 등의 데이터셋), 이미지넷 같이 큰 데이터셋은 모든 이미지의 에측값을 저장해 두는 것이 불가능하다.
따라서 큰 데이터셋의 경우에는 1번의 방법을 사용한다. 여기서 가장 큰 한계점이 나오는데, 저자들은 PS-KD를 소개 할 때에는 일반적인 방법으로 과거 t-1, t-2, ... 에폭의 모델의 예측값을 사용하는 것을
제시하였다. 하지만 이미지넷 실험에서 사용된 resnet152 같은 경우에서는 왠만한 GPU에 이 모델이 3개 이상 들어가지 않아 논문에서는 모두 한 에폭 전의 모델만을 사용했다고 한다. 또한 VRAM을 더 많이 
모델에서는 2개 이상 VRAM을 사용할 수없고 데이터셋 또한 크기 때문에 방법론이 PS-KD를 적용하기 힘들 가능성도 있다고 본다. 논문에서 제시한 일반적인 손실함수는 아래와 같다. \
$\mathcal{L}_{KD, t} (x, y) = H((1-\alpha) y + \alpha P\_{i < t}^S(x), P\_t^S(x))$ \ 
이 때 중요한 것은 $\alpha$가 하이퍼 파라미터가 아니라는 것이다. 따라서 t에폭에서 $\alpha$는 아래와 같의 정의된다.
$\alpha_t = \alpha_T \times \frac{t}{T}$ \ 
$T$는 총 에폭이고, t는 현재 에폭이다. 위의 PS-KD 손실함수에서 볼 수 있듯이 $\alpha$값이 커지면 과거의 정보에 더 의존한다고 할 수 있다. 하지만 훈련 초기에는 과거의 정보가 크게 의미가 없으므로
$\alpha$값이 작고, 모델이 훈련 될수록 모델의 성능이 좋아진다는 가정하에 과거의 모델에 가중치를 늘리는 것이다. 따라서 훈련이 끝나갈 때에 쯤에는 hard-label의 정보가 거의 없게 된다. 

### Theoretical support
증명 파트에서 말하고자 하는 것은 PS-KD가 그렇다면 어떠한 부분에 영향을 주는지와, 왜 $\alpha$값을 점진적으로 증가시켜야 하는 이유이다. 식 마지막 부분을 보면, 
$\frac{\sum_i |\partial_i^{KD, t}|}{\sum_i |\partial_i|} = 1  - \alpha (\frac{1 - p_{t-1, GT}}{1 - p_{t, GT}}) = 1 - \alpha(\frac{\gamma_{t-1}}{\gamma_t})$ \
$1-p_{t-1, GT}$는 모델이 t-1에폭에서 틀린 확률이므로, 위의 식 마지막 $\gamma$부분은 $\frac{t-1에폭 모델이 틀린 확률}{t에폭 모델이 틀린 확률}$이다. 이 값이 클수록 t-1에폭에서 틀린 확률이 
더 크다는 말이므로 모델이 더 향상되었다고 할 수 있고, 반대로 이 값이 작을수록 모델이 적게 향상 되었다고 할 수 있다. 모델이 많이 향상되었다는 것은 모델 입장에서 쉬운 sample들이 많이 존재한다는 
것이고, 반대로 모델이 적게 향상되었다는 것은 모델 입장에서 hard-sample이 많았다는 것이다. 따라서 $\alpha$를 키울수록 $\gamma$부분이 작아지므로 hard-sample을 더 많이 존재하는 효과가 있다. 
**즉, 훈련 후반에 모델이 학습하면서 $\alpha$값도 linear하게 커지게 설정함으로써 모델이 더 많은 hard-sample을 보도록 유도하고, 이는 좋은 regularizer 역할을 한다.** 


# Experiments
실험은 크게 3가지 task에서 진행했다. 
1. Image classification
2. Object detection => backbone만 갈아끼움
3. Machine Translation

### Image classification
가장 많은 실험결과를 보여준 task이다. accuracy 뿐만 아니라 confidence 성능도 축정하는 ECE, AURC를 사용하였다. 
![](/assets/images/2021-11-17-PS_KD/1.JPG)
5개의 모델에서 4개의 비교군을 사용하엿다. VGG는 없고, 사람들이 일반적으로 가장 많이 사용할만한 모델을 사용하였다. 일관적으로 좋은 성능을 보이고, LS보다 성능이 낮은 모델들을 비판함.

![](/assets/images/2021-11-17-PS_KD/2.JPG)
다음으로는 현실적으로 image classification을 할 때 많은 augmentation을 사용한다. 이러한 augmentation을 사용했을 때 augmentation만 사용하는 것보다 성능이 떨어진다면, 당연하게도 
제시한 방법론을 사용하지 않을 것이다. 위의 테이블에서, 성능 순서는 Baseline < Cutout < CutMix < PS-KD < CutMix + PS-KD < CUtout + PS-KD이다. 아주 이상적인 결과를 보여줌으로써
최신 augmentation방법들에도 잘 호환되는 것을 볼 수 있다.

![](/assets/images/2021-11-17-PS_KD/4.JPG)
필수적으로 들어가야 하는 이미지넷 성능이다. 여기서는 CutMix만 사용하는 것이 PS-KD를 사용하는 것보다 더 좋은 성능을 보였으나 둘 다 사용하는 것이 가장 좋은 성능을 보였다.

![](/assets/images/2021-11-17-PS_KD/5.JPG)
다음으로는 confidence의 성능을 명시적으로 보여준다. 첫번째 방탄 조끼 그림은 정확히 방탄 조끼만 있지만, baseline과 PS-KD가 모두 잘못된 예측을 하는 것을 보여준다. 하지만 잘못된 예측값에서 높은
confidence를 보여주는 Baseline에 비해 PS-KD는 낮은 confidence를 보여준다. \
두번째 그림은 여러 물체가 있다. 이 그림의 레이블은 Dutch oven이지만, 다른 물체 또한 포함되어 있으므로 멀티 레이블이라 할 수 있다. 오른쪽 표는 방탄 조끼 예제와 같이 두 모델 모두 잘못된 예측을 했으나
PS-KD가 사진속에 있는 모든 물체에 대하여 비슷한 confidence를 가지는 것을 보여준다.  

### Object Detection
![](/assets/images/2021-11-17-PS_KD/6.JPG)
object detection 실험도 간단히 진행하였다. 주목할만한 것은 실험을 할 때 backbone만 기본 imagenet pretrain을 사용한 것과 PS-KD로 훈련된 모델을 갈아 끼웠다는 것이다. 이렇게 하면 실험이 
굉장히 쉬워진다. 

### Machine Translation
![](/assets/images/2021-11-17-PS_KD/7.JPG)
image classification 말고도 완전히 개별적인 task를 또 하나 보여주었다. transformer를 활용하여 기계번억에도 적용해 보았다. 결과는 좋음.
