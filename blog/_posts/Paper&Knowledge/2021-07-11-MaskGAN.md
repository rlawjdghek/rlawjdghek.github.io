---
title:  "[CVPR2020]MaskGAN: Towards Diverse and Interactive Facial Image Manipulation"
excerpt: "[CVPR2020]MaskGAN: Towards Diverse and Interactive Facial Image Manipulation"
categories:
  - Paper & Knowledge
  
tags:
  - GAN
  
toc: true
toc_sticky: true
toc_label: "On this page"
use_math: true
    
last_modified_at: 2021-07-11T15:48:00-05:00
---

Motion animation을 연구하던 중 관련 논문 찾아보다가 Face부분에서 Mask segementation으로 Motion을 구현한 논문. 여기서는 사람 얼굴만 다루므로 Motion은 표정 = appearance로 볼 수 있다.

읽기전에 목표) source의 표정 + target의 identity를 합성한다.

### Abstract + Introduction
MaskGAN에서 주목할 모듈 및 단어는

1. Editing Behavior Simulated Training(EBST) : 그냥 훈련 과정을 멋드러지게 쓴것. 아직 네이밍 한것의 의도는 못찾음.

2. Dense Mapping Network(DMN) : GT data와 별도의 Mask를 받아서 별도의 Mask에 해당하는 표정과 GT의 Identity에 해당하는 합성이미지를 만듬.

3. MaskVAE : 이건 훈련과정 EBST에서 활용되기 전 미리 훈련한 VAE인데, 이 모듈의 목표는 Mask를 받아서 다시 Mask를 만드는 것. 근데 훈련과정에서는 중간에 나오는 식을 약간 변형한다.

4. Alpha Blending : Dense Mapping 거친 결과를 이용해서 모션에 해당하는 이미지 추출. 이걸 가지고 최종적으로 합성한다.

MaskGAN 만들라고 CelebAHQ로 mask annotation한 것도 만들었다는데 이건 안봐도 될듯.

### Our Approach

간단하게 training pipeline을 살펴보면
1. MaskVAE를 미리 훈련시킨다. MaskVAE는 structure prior의 manifold, 즉 원본에서 identity와 appearance를 분류하는 작업의 기초라고 볼 수 있다. (Mask가 들어가고 
인토커와 디코더 사이에 이걸 약간씩 조작하므로). 인코더는 1024의 $\mu$와 $\sigma$를 반환하는데 이걸 VAE 개념으로 $z = \mu + r \odot exp(\sigma)$로 합친다음, Decoder로 들어간다.

2. 본격적으로 훈련에 들어가면 맨처음으로 DMN에 GT data pair, 즉 원본 이미지와 ($I_t$) 이 원본의 Mask ($M_t$)를 쌍으로 하는 데이터와 별도의 마스크를 집어 넣는다. 그러면 원본 비슷한 이미지 (I_{out})가 나옴.
여기에 GAN loss, GAN feature loss, VGG loss로 역전파

3. 위의 2번과정이 stage1이라 제시한 기본적인 방법이고 DMN을 더욱 robust하게 만들고 합성하기 위해서 stage2를 또 거친다. Mask VAE로 들어간 뒤, 인코더에서 참조할 마스크 (z_{ref})를 이용해서 
$\pm \frac{z^{ref} - z^t}}{\lambda_{inter}}$로 $z_{inter}$, $z_{outer}$를 만든다. 이 두개를 디코더에 통과시켜 $M_{outer}$, $M_{inter}$를 얻는다. 그 다음 이 두개의 마스크와
GT data pair를 각각의 DMN에 넣어서 $I_{outer}$, $I_{inter}$를 얻고 Alpha blending에 넣어서 motion을 추출한 이미지를 얻는다. 그 다음 blend과정을 거치면 합성 영상이 된다. 이 합성영상과
다시 GT data pair로 GAN loss, GAN feature loss, VGG loss를 이용하여 학습한다.

4. 추론때는 DMN만 넣는다. 2번의 과정이 추론과정이라 할 수 있는데 먼저 우리에게 주어진 이미지는 원본이미지이고 여기서 마스크를 뽑을 수 있다. 또한 별도의 마스크가 우리가 조작하고 싶은 이미지 즉 source의 마스크라고 할 수 있다. 

### Modules
모듈은 읽었던 논문의 필기나 그림을 따라가면 훨씬 이해가 쉬움. 그림 잘 나와있어서 충분. 논문의 3페에지에 $F, \gamma\beta$는 각각 $I^t$가 SFT layer에 들어가기 직전이 F이고, $M^t$가 아래의 DMN 그림의 SFT layer직전에 들어가는 것을 
$\gamma, \beta$라고 하는 것이다. 연산은 단순히 $\gamma \odot F + \beta$.
![](/assets/images/2021-07-11-MaskGAN/1.JPG)