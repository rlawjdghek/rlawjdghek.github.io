---
title:  "논문 팁들"
excerpt: "논문 팁들"
categories:
  - Paper & Knowledge
  
tags:
  - Paper & Knowledge
 
published: False
toc: true
toc_sticky: true
toc_label: "On this page"
use_math: true
    
last_modified_at: 2021-08-14T15:33:00-05:00
---

### 마인드

가장 중요한 점 : 어떤 식으로 진행할지를 명확히 건설해 놓기. Section같은 큰 틀이 중요한 것이 아니라 기존 연구들을 소개하고 이러한 단점이 있어서 우리는 ~를 제시한다.
 또한 팩트를 기반으로 써야 한다. 가정, "어느 정도는~~" 이런말을 사용하지 말고 분량 생각하지 말기. 오히려 처음에 사실을 기반으로 틀만 제대로 잡아놔도 분량 늘리는 것은 쉽다. 
 분량이 늘어나는 것은 다른 자료를 기반으로 근거를 붙이는 것이지 내가 상상해서 쓰는 것이 아님.

또한

![](/assets/images/2021-08-14-paper_tips/1.PNG)
와 같이 사실을 1줄로 쓰지 말고 자신 있는 부분은 아주 자세하지만 사실에서 벗어나지 않도록 작성.

글을 쓸 때 최대한 쉽게 쓰려고 하자.  다른연구에서 제시한 사실을 그대로 써놔도 이미 한번 거친 것이기 때문에 새로 읽는 사람은 어렵게 느낄 수 있다. 또한 내가 제시한 사실을 쓰는 것은 읽는 사람이 더 어렵게 
느낄 수 있다. 반드시 한 paragraph를 쓸 때마다 써본거 다시 읽으면서 흐름이 자연스러운지 확인. 항상 내가 쓴 글이 검토 될 시간 없이 바로 올라간다고 생각하고 쓰자.

### 짧은 팁들

같은 접속사

비슷한 내용 => and, also, moreover, additionally, furthermore, addition, similarly, similar to

다른 내용 => but, however, on the other hand, in contrast, unlike

결론 => as a result, therefore, hence, subsequently

이유 => because 

$0.$ 용어를 계속 일관되게 사용하기. 계속 같은 말이 나와서 중복감이 심하지만 통일성이 없는 것보다는 낫다. 예를 들어 inter-class relationship prior를 inter-class similarity 등으로 변형하면 
뭐가 뭔지 알기 힘들다. 또 다른 예제로 soft targets가 맞는데 soft target으로 계속 바꿔서 쓰는것도 주의.

$1.$ 이해가 잘되고 명확하게 적는 대신, 빼먹은 것없이 자세히 적어야 한다. 분량이 남는 것은 충분히 설명하지 않았다는 것. 장황한 것이 아니라 필요한 정보를 많이 전달하는 것이 목표. 대신 문장 문장은 읽기 쉽고 간결해야 한다. 
이게 문장 자체가 길지 않아야 하는것이 아니라 우리가 말을 잘못할때 장황하게 하면 안된다는 것을 명심하자. 문장을 적을 때 계속 꼬인다면 아예 처음부터 다른관점으로 적는 것도 좋다. 예를 들어 어떤 equation을 설명할때 똑같은 단어를
계속 사용하면, 문장 문장이 똑같아 보이고 좀 더럽게 느껴진다. 이런 경우는 맨 처음 그 용어를 문자로 정의하거나 가장 큰 의미를 먼저 적으면 뒤에서는 두 세번 설명하지 않고 문자를 활용하거나 길이 이어지듯이 문장을 쓸 수 있다.

$2.$ 수식을 설명하거나 메소드에서 수식이 나올 경우 아예 모든 것을 문자화 해서 문자를 활용하자. 글로하면 진부해보이고 명확하지 않음.

$4.$ abstract는 citation 안쓴다.

$5.$ "equation explain ... " 은 이상한 문장. equation이 설명하는 말이므로 말이 안된다.

=> equation indicate / is defined / represent / describe

$6.$ This result is important/essential result. 

7. 문장은 무조건 짧게 쓸려고 해라.

8. "et al." 은 한개의 단어라고 생각하자. 즉, "."을 꼭 붙인다. 

 

9. 저자 3명 이상일 때는 "et al."을 꼭 붙인다. 

ex) Woo -> Woo,

ex) Woo, Kim -> Woo and Kim

ex) Woo, Kim, Lee -> Woo et al.

 

10. 절대 줄임말 쓰면 안됨.

ex) can't => cannot

ex) let's => let us

 

11. get 절대 쓰면 안됨. 너무 broad한 단어.

 

12. since/because => , since/, because . 즉 항상 쉼표 붙이기 

 

13. 대체적으로 Figure는 caption이 밑에, table은 위에

 

14. 다른 논문을 인용하기 위해 문장에 쓸땐 영어를 같이 써준다. 

ex) by [1]. => by work [1]. 

 

15. 정의를 쓸 땐 그냥 베껴라. 대신 표시는 해두자.

 

16. 위키피디아의 글을 이용하되 절대 참조는 하면 안된다.

 

17. active한 문장을 써야한다. (grammerly에서 추천하는 것이 맞다.)

 

18. 논문을 읽을 때 좋은 문장, 논문의 구조를 파악하려 하자. 만약 좋은 문장이 있으면 저장해 두었다가 약간 수정해서

쓰자.

 

19. "that is" 다음엔 쉼표를 찍어야한다.

 

20. "A versus B" => "A vs. B". vs.는 단축어이므로 온점을 찍어야 한다.

 

21. 공식 앞에 : 붙이기

ex) ... as follows: 

    A=B * C

 

22. show = demonstrate = illustrate = present = depict = describe = represent

 

23. Self-Attention or self-Attention 둘다 맞지만 중요한 건 논문에서 일관성 있게 한 단어만 써야한다.

 

24. 논문에서 내가 이해 못하는 것은 절대로 넣으면 안된다. 모든 것을 방어할 수 있어야한다.

 

25. 문장 베낀거 바꾸는 법.

1) 능동 <-> 수동

2) 주어, 동사 바꾸기

3) 문장 끊거나 붙이기

4) 유사어

 

 

26. 논문에 있는 모든 문장은 이유가 있어야 한다.

 

27. That is, learning only from the core tensors is sufficient for differentiating real and fake images.

=> In other words, learning mainly/primarily from the core tensors is important/critical for distinguish/dividing betwwen real and fake images

28. 디테일 한 것 까지 다 챙기기. 나중에 데드라인 지나고 나면 후회한다.

 

29. 공식 다음엔 쉼표, 그 후에 where로 변수 설명. 문장이 공식으로 끝나면 온점으로 마무리.

 

ex) A=B*C,

 

where ....

 

30. 어떤 단어를 쓸까 할 땐 구글에서 몇개의 문서가 검색되었는지 이용.

 

ex) lack of 14800000 vs. lacking of 150000 이면 lack of 가 맞는 표현이다.

 

31. There are many research work. => work에는 s를 안 붙이는데 복수로 표현된다.

 

32. Because/Since Lee and Kim [2] use an attention transfer function, their performance is much better compared to

baseline EfficientNets.<=> Their enhanced performance compared to baseline EfficientNets are mainly due to (/attributed to / ascribed to) the attention transfer function.

<=> By leveragin/appying/useing/incorporating an attention transfer function, their performance significantly improved compared to that of EfficientNets.

33. 위에서 that of 를 썼듯, 내가 항상 고민하는 영어 표현, 사과의 맛과 귤의 맛을 비교해야 하는데 flavor를 2번 쓰기 싫은 것을 해결해주는 표현. 

 

34. "i.e." <=> that is (즉), "e.g." <=> for example (예를 들어)

 

ex) There exists many deepfakes datasets. (e,g, Faceswap, NT and etc.)

35. A: B

 

1) A와 B가 cause and effiect 관계

2) B가 A에 대한 list

ex) our contribution are as follows: firstly [...]; secondly, [...]; 

3) equation

36. A; B

 

1) A와 B를 and로 이을 수 있는데 그러면 문장이 너무 길어지거나 끊어도 되는데 그러면 너무 짧아 지는 경우에, 즉, 문장 길이가 애매할 때 쓴다.

2) ; 다음에 however, for example, that is 등등 A에 대한 부가 설명이 B에 나올때 쓴다. 그러면 그냥 온점으로 끊는 것이랑 무엇이 다른가=> 끊어도 되는데 더 약하게 끊고 싶을때. 온점으로 끊는 것이 더 강한 표현.

3) B가 솔로 문장으로 쓰이기에 좀 짧다 싶을 때

37. "et al."은 한개의 단어로 생각.

 

38. render 사용법 (가장 기본적으로는 make와 같다고 보면 된다. 추가적으로 형용사로만 존재하는 단어 (ex) robust)를 make를 사용하고 싶을 때 render를 사용하면 된다.)

A render B

ex) The lack of data renders (makes) the training difficult.

ex) It renders the transfer learning more robust during the trianing process.

ex) Attention transfer renders feature matching easier than before.

ex) Through KD, our machine unlearning approach renders the training optimization process faster. 

<=> Through KD, our machine unlearning apporach accelerates the training optimization process.

 

39. Note that -> Note, 맨날 Note that하면 진부하다.

 

40. wide range of tasks => 진부하지 않은 표현

 

41. order of magnitude => 정확한 정의는 수학에서 
α
 이지만 이 논문에서는 outperform으로 나타냄. 하지만 context마다 다른 표현이 된다. 

 

42. experiment는 항상 복수 => experiments

 

43. During the training (x) During training (o)

 

44. 문단 시작할때 다른 단어를 쓰도록 노력. ex) We-> However, To comply ...

 

45. on par : 비교 할때 쓰는데 similar, comparable 이라는 의미로 쓴다.

 

46. demonstrate the superiority : outperform 대신 진부하지 않은 표현

 

47. this confirm finding of adding linear : Linear를 쓴 것이 더 좋다는 뜻.

 

48. hypothesis->believe로 쓰자. 뭔가 좀 더 가정하는 것보다 완화된 표현이라 생각된다.

 

49. underperform : A outperforms B <=> B underperforms A 이지만 outperform의 진부하지 않은 표현

 

50. 내 문장 -> 교수님 문장

 

We can observe that visualized CAM is activated on face region. Compared with \textit{Resized}, blurred images yield more broadly activated CAM. Therefore, features are more smoothly distributed, and model can be confused about classifying with real and fake. In results, it causes the weak performance. (see Table.~
???
)

====>

We can observe that visualized CAM is activated on face region, compared to \textit{Resized}, and Gaussian Blur tends to yield more broadly activated CAM outputs, as shown in Table.~
???
, and Fig.~
???
. Therefore, features are more smoothly distributed, and it demonstrates that the detection model can be confused about classifying with real and fake, resulting the overall low performance. 

 

51. 인터넷 기사나 조사기관에서 발표한 내용 참조하기

@misc{WHO_falls,
   title={TRY THESE 10 AMAZINGLY REAL DEEPFAKE APPS AND WEBSITES},
   howpublished = {\url{https://www.analyticsinsight.net/try-these-10-amazingly-real-deepfake-apps-and-websites/}},
   author={Meenu EG},
   year={2021},
   publisher={Analytics Insight},
   note = {Accessed: 2021-05-21}
}

기사에 위 해당하는 내용만 바꿔서 적으면 된다.

 

52. a lot of research -> much research

 

53. some 사용하지말기. 너무 broad하다. 

 

54. Research는 항상 단수로 쓴다

 

55. Abstract는 참조 잘 안 씀

 

56. Abstract에서 마지막에 뭘 보여주는지는 썻고 우리가 뭘 찾았는 지까지 써 준다.

 

57. Best 같이 최상급의 단어를 쓸 땐 주의하자. 특정 객체를 가리키는 것은 제대로 언급할 수 있는 때 쓰는 습관. Popular 로 고치심

 

58. 숫자 천자리마다 쉼표 찍어주기

59. \documentclass[sigconf,review,anonymous ]{acmart} latex에서 리뷰받을때 맨 처음에 사용하면 좋다. 저자에 anonymous author 뜨고 acknowledgement 적용이 안됨.

### 좋은 문장들

#### Abstract

1. Time series outlier detection has been extensively studied with many advanced algorithms propsed in the past decade. [Revisiting time series outlier detection: definitions and benchmarks.]

2. <u>Learning similarity functions between image pairs with deep neural networks yields highly correlated activations of large embeddings.</u> [BIER-Boosting Independent Embeddings Robustly.]

3. <u>Our method does not introduce any additional parameters and works with any differentiable loss function.</u> [BIER-Boosting Independent Embeddings Robustly.]

4. We evaluate our metric learning method on image retrieval tasks and show that it improves over state-of-the-art methods on Cars-196 and VehicleID datasets <u>by 
a significant margin</u> [BIER-Boosting Independent Embeddings Robustly.]

5. <u>Riding on the waves of deep neural networks,</u> deep metric learning has achieved promising results in various tasks by using triplet network or Siamese network. [Hard-Aware Deply Cascaded Embedding.]

6. Recently, <u>a popular line of research</u> is to incorporate margins in well-established loss functions in order to maximise face class separability. [ArcFace: Additive Angular Margin Loss for Deep Face Recognition]
=> "최근, 많은 연구들은~" 하는 것보다 더 희귀한 표현. 

7. <u>Examples include</u> distilling a large network into a smaller one, transferring knowledge from one sensory modality to a second, or ensembling a collection of models into a single 
estimator. [Contrastive Representation Distillation.] => "For example, ~" 같은 진부한 표현보다 강렬하게 abstract에서 표현 하고 싶을때 사용하면 좋아 보인다. 




#### Introduction
    
1. CCTV surveillance and the facial recognition technology is <u>on its way</u> to becoming ubiquitous in large cities around the world. [Understanding the Privacy
of Facial Recognition Embeddings.]

2. In this paper, <u>our goal is twofold</u>; we investigate ...

3. <u>With the hope that</u> these insights could motivate future work, we have open-sourced all the datasets, the pre-processing and synthetic scripts, and the algorithm implementation in TODS. 
[Revisiting time series outlier detection: definitions and benchmarks.]

4. However, <u>their unstructured nature</u> combined with the complexity and ambiguity of natural language <u>pose</u> a challenge when using radiology reports for clinical research and other downstream applications, 
especially in settings with limited labeled data. [RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.]

5. We define a novel information extraction schema for radiology reports, <u>intended to cover modest climically relevant information with in the report while allowing for ease and consistency during annotation.</u> 
[RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.]

6. <u>Along with these datasets</u>, there have been many advancements in NLP for the task of entiy and relation extraction. [RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.]

7. <u>To address this issue</u>, we present a learning approach, called BIER. [BIER-Boosting Independent Embeddings Robustly.]

8. <u>In our evaluation,</u> we show that BIER significantly reduces the correlation of large embeddings and works with several loss function <u>while increasing retrieval accuracy
by a large margin.</u> [BIER-Boosting Independent Embeddings Robustly.]

9. <u>BIER does not introduce any additional parameters into a CNN and has only negligible additional cost during training time and runtime.</u> [BIER-Boosting Independent Embeddings Robustly.]

10. Moreover, the commonly available class assignments <u>give rise to</u> image relations aside from the standard, supervised learning task of "pulling" smaples with identical class labels together
while "pushing" away samples with different labels. [DIVA: Diverse Visual Feature Aggregation for Deep Metric Learning]

11. We <u>tackle the issue</u> of generalization in DML by designing diverse learning tasks complementing standard supervised training, leveraging only the comonly
provided training samples and labels. [DIVA: Diverse Visual Feature Aggregation for Deep Metric Learning]

12. <u>To tackle them</u>, we propose a residual learning framework to make the learning process stable and efficient. [Distilling Knowledge via Knowledge Review.] 

13. Whereas the knowledge distillation enables utilizing the large network <u>in a condensed manner</u>, the inference on such large network, a.k.a. the teacher network, <u>becomes an ultimate burden of its 
practical usages.</u> [Refine Myself by Teaching Myself: Feature Refinement via Self-Knowledge Distillation]

14. Our normalization enjoys following favorable properties. [Spectral normalization for GAN]
=> 진부하게 our main contributions are as follows 보다 나은듯.

15. However, stat-of-the-art models usually involve very deep networks with tremendous parameters and a large number of floating point operations, <u>which hinders them from real-world applications on 
low-resource devices, such as smartphones and wearable gadgets.</u> [Data-Distortion Guided Self-Distillation for Deep Neural Networks.]
=> model compression introduction에 어울리는 문장.

16. To better train a small network, model distillation, i.e., <u>*teacher-to-student* mechanism that directly trains a student network to inherit the knowledge (e.g., class probabilities), logits,
intermediate feature maps, attention map of a deeper or more complex teacher network</u >, has been introduced. [Data-Distortion Guided Self-Distillation for Deep Neural Networks.]
=> model compression introduction에 어울리는 문장. 

17. It remains unclear how a teacher model boost another model <u>in principle.</u> [Data-Distortion Guided Self-Distillation for Deep Neural Networks.]
=> "in principle"이라는 표현, 대체적으로, 원론적으로, 이론상으로는 이라는 뜻으로, 사용하면 좋은 듯. 

18. These shortages motivate us to develop a new mechanism that directly optimizes student network to reach a more desired solution from the raw training data without going
through another teacher or intermediate network. [Data-Distortion Guided Self-Distillation for Deep Neural Networks.]
=> 왜 이런 생각을 하게 되었나. motivation 늘릴때 좋은 표현. 

19. For dataset generation, we collected 294.713 frames from 178 videos filmed at 49 different locations, representing <u>rich backgrounds and diverse environments.</u>
=> diverse라는 말이 자주 사용되는데 rich라는 표현도 좋은듯. [VFP290K: A large-scale benchmark dataset for vision-based fallen person detection.]

20. There are, therefore, <u>significant efforts underway</u> to develop forensic techniques to detect synthesized or manipulated audio, image, and video recordings. [Evading Deepfake-Image Detectors with
White- and Black Box Attacks.]
=> underway는 진행중인이라는 형용사인데 efforts 뒤에 사용되었다. 어떤 문제를 해결하기 위해 진행되는 노력들을 나타낼 때 좋은 표현인듯. 

21. These face GANs <u>are capable of</u> generating faithful faces with a high degree of variability, and thereby providing rich and diverse priors such as geometry, facial textures and colors,
making it possible to jointly restore facial details and enhance colors. [Towards Real-World Blind Face Restoration with Genrative Facial Prior.]
=> ~ 할 수 있다는 표현을 be capable of 로 사용. 명사가 오면 capable of로 사용한다.

22. AdaConv can replace AdaIN in virtually every application where <u>the latter</u> has been adopted, providing a new, generic building block in CNN-based image generation and style manipulation. 
[Adaptive Convolitions for Structure-Aware Style Transfer]
=> 같은 단어 2번 반복 막기

23. To counter its computational expense, we also propose executing all regularizations less frequently, observing that this can be done without <u>compromising</u> effectiveness. [Analyzing and Improving the 
Image Quality of StyleGAN]
=> compromise는 사전에서 타협하다라는 뜻으로 많이 쓰이는데 여기서는 손상시키다 라는 뜻으로 쓰였다. 나중에 performance decrease 같은단어 진부할때 사용.

#### Background

1. Figure.3 illustrates the thress types of outliers that often serve as a <u>de-facto-standard</u>: [Revisiting time series outlier detection: definitions and benchmarks.]


#### Related work

1. A <u>central limitation</u> of both of these approaches is that they require task-specific datasets to be densely annotated by domain experts. [RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.]

2. Image embedding falls <u>under the unbrella</u> of distance metric learning. [Deep Randomized Ensembles for Metric Learning.]

3. THe main objective of metric learning in Computer Vision is to learn a function which maps a k-dimensional input vector, which is typically an input image or a feature representation of an image, 
into a d-dimensional vector space. [BIER-Boosting Independent Embeddings Robustly.] -> related work 맨 처음에 사용할때 좋다. 

4. They <u>leverage</u> the benefits of deeply supervised networks <u>by employing</u> a contrastive loss function and train lower layers of the network to handle easier examples, 
and higher layers in a network to handle harder examples. [BIER-Boosting Independent Embeddings Robustly.]

5. <u>In the work of Hinton et al.,</u> knowledge is defined as the teacher's outputs after the final softmax layer. [Knowledge Distillation via softmax Regression Representation Learning]

6. <u>The rationale behind</u> is the use of extra supervision from teacher model in teacher model in target model training, <u>beyond</u> a conventional supervised learning objective such as the
CE loss subject to labelled training data. [Knowledge Distillation by On-the-Fly Native Ensemble.]: 어떤 것이 좋다 또는 나쁘다는 이유를 들 때 좋은듯.

7. These representations could then be fine-tuned with a few labels for a supervised <u>downstream</u> task. [A self supervised styleGAN for classification with extremely limited annotations] 
=> 어떤 큰 범주의 하위 집단 task를 표현할 때 좋은듯. 여기서는 supervise task의 한 원소로 few shot learning을 설명함. 

  
#### Methods

1. <u>In what follows</u>, we first describe the details of the synthetic datasets and the real-world datasets, and then <u>elaborate</u> on the included algorithms. [Revisiting time series outlier detection: definitions and benchmarks.]

2. <u>As opposed to learning a distance metric,</u> in our work we learn a cosine similarity score which we define as dot product between two embeddings. [BIER-Boosting Independent Embeddings Robustly.]

3. <u>Let us denote by p the output of the teacher network when fed with some input image x.</u> [Knowledge Distillation via softmax Regression Representation Learning]

4. We refer to $"\odot""$ <u>as nesting of functions</u> where $gf\odot f (x) = g(f(x))$. [Distilling Knowledge via Knowledge Review.] -> 합성 함수 영어로.

5. We define a function $f$ which projects data space $\mathcal{D}$ to the embedding space $\mathcal{X}$ by $f(\cdot, \theta): \mathcal{D} \rightarrow \mathcal{X}$, where
$f$ is a neural network parameterized by $\theta$. [Embedding Expansion: Augmentation in Embedding Space for Deep Metric Learning.]
=> Representation Learning 문장에 좋은 표현인듯.

6. In the following section we display the practical benefits of our new algorithm, and we provide an <u>in-depth</u> comparison of its behaviour and that of traditional GANs. [WGAN]
=> in-depth는 심도있게라는 표현. extentional experiment라는 표현이 진부할때 사용하면 좋을듯.

7. After that, the modulation is <u>is carried out</u> by scaling and shifting the GAN features.[Towards Real-World Blind Face Restoration with Genrative Facial Prior.]
=> carry out이라는 표현을 conduct대신에 사용하면 좋을듯 

8. Therefore, we can observe that the classes within the same super-class makes squares along the diagonal-region demonstrating high correlation. [동근님 문장]
=> 20개의 super-class, 각각의 super-class마다 5개의 sub-class를 가진 CIFAR100에서 pearson correlation을 그리면 같은 super-class에 속한 클래스들이 높은 상관관계를 보이면서 대각선에 정사각형이 생기는데 이를 표현한 문장. 
e
9. Therefore, Eq.3 is <u>simplified</u> as follows: [교수님 문장]
=> 이 문장에서는 주어진 3번 식이 follows 단어 다음 식으로 유도되는 것을 의미하는데, 의미에 따라 simplified라는 단어로 사용하도록 하자. defined는 새로운것을 제시할때나 진리를 적을 때 쓰자.

10. Interestingly, <u>through systematic evaluations</u>, we find that using internal patches only outperforms using external patches. [Contrastive Learning for Unpaired Image-to-Image Translation.]
=> extensive experiment보다 그냥 돌려서 비교한 것이므로 systematic evaluation이 적합한듯.


#### Experimental Results

1. Due to the space limitation, the detailed benchmark results of synthetic datasets <u>are tabulated</u> in Appendix D. [Revisiting time series outlier detection: definitions and benchmarks.]

2. Except for the web attack dataset, all of other datasets <u>are dominated by</u> AR, IForest and OCSVM.

3. We <u>report</u> the full results for the benchmarks across entity types in Table 4 and across relation types in Table 5.

4. IE-KD is a very <u>general framework for knowledge transfer between any type of networks and training strategies.<\u> [Revisiting Knowledge Distillation: An Inheritance and Exploration Framework.]
=> 우리 method가 일반적으로 많이 쓰일 경우 이런 표현도 가능하다. 

5. Table 5 reports both the speed-up and compression rate obtained by various FitNets w.r.t. the teacher model <u>along with their number of layers, capacity and accuracies.</u> [FitNets: Hints For Thin Deep Nets.]
=> along with을 활용하는 문장.

6. Even at the end of the training, as Figure 7h, the heatmap of EE + triplet loss still contains <u>a greater number of hard negative pairs than triplet loss does.</u> [Embedding Expansion: Augmentation in Embeggin Space for Deep Metric Learning]
=> than 이후에 명사가 아닌 구가 온다. 비교하는 문장 적을때 사용하면 좋을듯.

7. Error decreases our proposed techniques <u>superimpose</u> over on another.
=> ablation같은데서 우리가 제시한 방법론이 한개씩 겹쳐지는 것을 표현하기 위해 superimpose라는 단어를 사용.

8. In contrast, as demonstrated in the attacker scenario, the fake images pre-processed by our method successfully evade the detector, <u>dropping accuracy to 0.5499, 0.6182, and 0.5717 for each GAN-based method.</u> [Under review].
=> 정확도가 몇에서 떨어질때 이런 표현 사용하면 좋은듯. 

9. Moreover, in the VGG family as teacher networks, there are marginal performance improvements in the three smallest models, VGG8, VGG11, and VGG13, 
but <u>a gradual decrease in the performance of the teacher network as the capacity increases.</u> [IMF]
=> ~할수록 ~는 ~하다. 여기서는 teacher의 크기가 올라갈수록 성능은 떨어진다는 말을 하는데, more and more은 동화에서 나오는 표현이라고 함. as를 활용하자.

10. In particular, we expect TimeGAN to <u>excel in<\u> capturing conditional distributions over time. [TimeGAN]
=> excel in : ~에 뛰어나다. 

#### Discussion

1. <u>Given that existing information extraction systems for radiology reports often suffer from a lack of report coverage,</u> we measure the number of tokens and sentances in report sections covered by our schema.
 [RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.]

2. For future work, we plan to extend our research for different medical multimedia data and apply other anonymization methods, such as differential privacy, which we did not formally consider.
[PTD: Privacy-Preserving Human Face Processing Framework using Tensor Decomposition]





#### Conclusion




 
 