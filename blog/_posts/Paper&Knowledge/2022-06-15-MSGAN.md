---
title: "[CVPR2019]Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis"
excerpt: "[CVPR2019]Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis"
categories:
  - Paper & Knowledge
  
tags:
  - GAN
 
published: True
toc: true
toc_sticky: true
toc_label: "On this page"
use_math: true
    
last_modified_at: 2022-06-15T15:04:00-05:00
---

Mode Collapse를 해결하는데에 있어 구현이 쉽고 효과적이라 가장 많이 사용되는 논문이다. Generator의 손실함수에 MS loss만 붙이면 되므로 아주 쉽다. 구현 보다는 저자들이 말하는 내용위주로 보자.
구현은 굉장히 간단하지만 GAN의 본질적인 문제인 mode collapse에 대하여 많이 언급하면서 분석을 더하였다. 또한 DRIT++, STARGANv2, InfinityGAN등에서 사용하였다는 것을 미루어볼 때, 왠만한 문제에서는
mode collapse를 줄이고 diversity를 늘리기 위해 들어간다고 볼 수 있다. 또한 GAN을 구현하면서 느낀 것이지만, 저자들이 배포한 공식 코드에서 약간의 변형만 생겨도 mode collapse가 발생한다. 개인적인
생각으로는 GAN의 수렴 안정성은 많이 개선되었지만, 아직 mode collapse에 대해서 완전히 자유로운 것은 아니다. 특히, 논문에서 언급한 대로 conditional GAN 문제에서는 더욱 심각하다.

# Abstract & Introduction
Conditional generation task는 GAN의 출현 이후로 굉장히 발전하였다. 하지만, 최근 content + style 접근으로 발전하는 GAN에서 빈번히 발생하는 것은 강력한 content에 대한 mode collapse이다. 특히 이것은
conditional GAN에서 더욱 심하게 발생한다. 예를 들어 고양이를 개로 변환하는 I2I translation을 할 때, 입력으로 들어오는 고양이의 이미지에 담긴 정보가 굉장히 많으므로 모델이 content 정보만 
배우려는 습성이 있다. 이 과정에서 **style을 담당하는 noise vector가 무시되고, 결국 특정 style에서만 잘 생성하는 mode collapse**가 발생한다. 

MUNIT, DRIT++ 등의 출현 이후에 대부분의 GAN 모델은 multimodal로 접근하여 이미지의 다양성을 늘리고 multi-domain에서 작동한다. 본 논문에서의 multimodal의 정의는 "a single input context corresponds to multiple plausible outputs."로,
한개의 context (=content)에 대하야 다양한 output을 생성할 수 있다. 예를 들어 CycleGAN 같은 경우는 one-to-one mapping으로 noise의 개념이 들어가 있지 않아 한개의 input에 대하여 고정적인 output을 도출해낸다. 이는 multi-domain과는 다른 
개념으로, multi-domain은 AFHQ 데이터셋처럼 개, 고양이, 야생동물 로 인지적인 관점에서 완전히 다른 이미지들의 클러스터이지만, multi-modal은 고양이 중에서도 다양한 종의 고양이를 생성할 수 있는 능력을 말한다.

기존 mode collapse를 방지하는 방법론들은 auxiliary classifier나 추가적인 encoder를 붙여 완화하지만 이는 구현도 복잡해지고, GAN에서의 핵심적인 문제인 모델의 크기를 줄일 수 있다는 한계점이 존재한다. 

본 논문에서는 mode collapse를 방지하는 효과적인 regularization을 더한 모델, MSGAN을 제시한다. MSGAN은 generator가 minor한 mode에 더욱 가중치를 두어 학습하게 하여 mode collapse를 방지하는 효과를 준다.
이는 생성 이미지의 diversity를 늘리지만, 이미지의 퀼리티는 유지하여 결과적으로 GAN 모델을 효과적으로 향상시킨다. 또한 기존 mode collapse를 줄이는 관련 연구들과 달리 overhead나 추가 메모리 사용이 거의 없다. 

[](/assets/images/2022-06-15-MSGAN/1.JPG)
# Method 
### Preliminaries
먼저 본 논문에서 해결하려는 mode collapse가 왜 일어나는지에 대한 분석을 해보면, 
mode collapse는 mode가 부족할 때 penalty를 주지 않아서 발생한다. 자세히 말하면, 모든 모드는 비슷한 disciminative value를 갖는다. 이 때 더 큰 mode (자주 발생하는 mode)는 훈련 과정중 더 discriminative score를 낮추기 위해 
학습되고, 이는 더 큰 mode를 초래한다. 

Conditional GAN의 경우에는 다른 관점이 있다. 초기 condition은 noise vector에 비하여 완성된 정보량을 갖고 있다. 이는 generator가 많은 것을 배울수 있는 도구로 사용될 수 있고, 초기 generator가 content에 의존하게 되어
noise vector를 무시할 수 있다. 이러한 경우 특정 noise에 대해서만 다른 스타일을 가지거나, 입력 content와 크게 다르지 않은 이미지를 생성할 수 있다. 

### Mode Seeking GANs
위의 그림이 직관적으로 가장 잘 설명된다. 두개의 latent vector $z_1$과 $z_2$가 고정되어 있다고 하자. 이상적인 real data에 대해서는 같은 z라도 mode가 골고루 분포되어 있어 다른 이미지가 나온다. 반면,
두번째 그림과 같이 mode collapse가 발생하면 이미 $M_2$에 대하여 collapse가 발생하였기 때문에 비슷한 이미지가 등장한다. 즉, 같은 길이 $|z_1 - z_2|$에 대해서 mode collapse의 경우에는 생성 이미지의 거리 
$G(c, z_1) - G(c, z_2)$ 가 작아진다. 즉, 생성 이미지간의 거리가 늘어나는 것이 좋으므로 손실함수는 아래와 같이 정의할 수 있다. 
\begin{equation}
\mathcal{L}_{ms} = max(\frac{d_I(G(c, z\_1), G(c, z\_2))}{d_z(z\_1, z\_2)})
\end{equation}
주의해야 할것은 우리는 이 값을 maximize해야 하므로 실제 구현에서는 음수가 붙는다. 

# Evaluation Metrics
본 논문에서는 MSGAN이 3가지의 subtask에서 FID, LPIPS, JSD & NDB를 활용하여 평가한다. 
NDG, JSD 평가 방법을 정리하면 아래와 같다. 
1. 훈련 데이터셋 샘플들을 K-means 클러스터링 한다.
2. 생성 이미지들을 nearest neighbor로 훈련데이터셋의 클러스터에 배정한다.
3. 훈련 데이터셋 샘플과 생성 이미지 각각의 bin배율을 계산한다. 즉, 생성 이미지들이 한 클러스터에 모이면 mode collapse를 의미한다.

subtask별로 평가 방법을 정리하면 아래와 같다.
### Conditioned on Class Label
MNIST데이터셋을 생성하는 task라고 보면 된다.
##### FID
1. 레이블마다 5000장의 이미지를 생성한다.
2. 모든 훈련데이터와 FID를 계산후 평균한다.
##### NDB, JSD
1. 레이블마다 생성된 5000장으로 k=250개의 클러스터로 계산한다.

### Conditioned on Image
본 논문에서는 pix2pix와 BicycleGAN을 사용하였다. 구현 방식은 약간 바뀌었는데, z를 도입해야 하므로 아래와 같이 generator의 입력을 바꿨다.
```python
self.z_random1 = self.get_z_random(self.real_A.size(0), self.opt.nz)
self.z_random2 = self.get_z_random(self.real_A.size(0), self.opt.nz)

fake_B = self.netG(torch.cat((self.real_A, self.real_A), 0), torch.cat((self.z_random1, self.z_random2), 0))
self.fake_B_random1, self.fake_B_random2 = torch.split(fake_B, self.z_random1.size(0), dim=0)

self.fake_B_random1_condition = torch.cat((self.real_A, self.fake_B_random1), 1)
self.fake_B_random2_condition = torch.cat((self.real_A, self.fake_B_random2), 1)

self.real_B_condition = torch.cat((self.real_A, self.real_B), 1)
```
##### FID
1. 테스트셋에서 100장의 이미지를 추출한다.
2. 이미지당 50장을 생성한다.
3. 1,2에서 생성한 총 5000장과 모든 훈련데이터와 FID계산 후 평균
##### LPIPS
1. 모든 test에 대하여 장당 50장을 생성한다.
2. 생성된 50장에서 50개의 pair를 만들고 LPIPS 계산후 평균.
3. 모든 test에 대하여 평균한다.
##### NDG, JSD
1. FID에서 생성한 5000장을 facade 데이터셋은 k=20으로 클러스터링, 나머지 데이터셋은 k=50으로 클래스터링

### Conditioned on Text
##### FID
1. 테스트셋에서 문장 200개 추출
2. 각 문장당 10개의 이미지 생성
3. 1,2에서 생성한 총 2000장 이미지와 훈련데이터에서 추출한 2000장과 FID 계산후 평균.
##### LPIPS
1. 테스트셋에서 문장 200개 추출
2. 각 문장당 10개의 이미지 생성
3. 10장에서 10개의 쌍을 만든뒤 LPIPS 계산 후 평균
##### NDG, JSD
1. FID에서 생성한 2000장의 이미지로 k=100개 클러스터링

[](/assets/images/2022-06-15-MSGAN/2.JPG)
위의 그림은 bin proportion을 시각화 한 것이다. DRIT은 처음 모드에 굉장히 많이 분포되어있지만, MSGAN은 전체적으로 고르게 분포되어 있다. 




