---
title: "[ICLR2021]Denoising Diffusion Implicit Models"
excerpt: "[ICLR2021]Denoising Diffusion Implicit Models"
categories:
  - Paper & Knowledge
  
tags:
  - Diffusion Models
 
published: True
toc: true
toc_sticky: true
toc_label: "On this page"
use_math: true
    
last_modified_at: 2022-12-03T15:04:00-05:00
---
DDPM과 DDIM의 샘플링을 도식화 한 그림.
![](/assets/images/2022-12-03-DDIM/1.jpg)
DDPM의 가장 큰 문제점인 샘플링 속도를 어떻게 줄일 것인가를 해결한 논문. 이 방법론을 생각하게 된 흐름을 추측하자면, 논문의 eq. (11)의 joint probability의 차이

# Abstract & Introduction

훈련 모델은 DDPM을 그대로 사용한 대신, 샘플링 알고리즘에서 단순히 sample timestep (DDPM에서는 1000)을 줄이는 것이 아닌, 약간의 deterministic을 추가하여 샘플링 속도를 향상시켰다 (논문 eq. (7)의 시그마). 즉, markovian인 DDPM을 non-markovian으로 변형하여 stochastic-deterministic의 트레이드오프를 조절한 논문. 

Deterministic을 추가함으로써 가지는 장점은 아래 4가지로 정리할 수 있다.
1. 추론 시간
2. 샘플 quality
3. consistency 발생 ==> 같은 latent에서 시작하면 generative process가 다르다 해도 비슷한 high-level이 생성.
4. DDPM은 3의 성질이 적기 때문에 stochastic한 성질이 강했다. 하지만 DDIM은 3의 성질로 인하여 GAN과 같이 latent의 보간이 가능하다.

# Background
notation부터 정리하자.
1. DDPM논문에서 사용한 $\bar{\alpha}$가 여기서는 $\alpha$로 표시됨.
2. inference distribution, inference procedure : $q(x\_{1:T} \| x\_0)$.
3. forward process : $q(x\_{t} \| x\_{t-1})$
4. generative process, reverse process : $p\_{\theta}(x\_{0:T})$

DDPM에서도 잘 정리되어 있으나, 본 포스팅에서도 notation등이 바껴서 중요한 식들은 적어둔다. 
\begin{equation}
q(x\_t \| x\_0) = \mathcal{N}(x\_t; \sqrt{\alpha_t}x\_0; (1-\alpha_t)I)
\end{equation}

이는 다음 식과 같다
\begin{equation}
x_t = \sqrt{\alpha_t}x\_0 + (1-\alpha_t)\cdot \epsilon
\end{equation}
where $\epsilon \sim \mathcal{N}(0, I)$.

또한 DDPM에서 제시하는 손실 함수는 아래와 같다. 
\begin{equation}
L(\epsilon_{\theta})=\sum_{t=1}^{T}\mathbb{E}[\parallel \epsilon_{\theta}^t(\sqrt{\alpha_t}x\_0) + \sqrt{1-\alpha_t}\epsilon_t 
\parallel_2^2]
\end{equation}

# Method
Method의 전체적인 흐름은 아래와 같다.
1. deterministic한 성질을 더하기 위한 새로운 $q\_{\sigma}(x\_{t-1} \| x\_t, x\_0)$를 정의한다. 이 때, DDPM의 훈련 알고리즘을 그대로 사용하기 위해서 DDPM에서 정의한 기저 성질(forward process $q(x\_{t-1} \| x\_t)$ 등)이 달라지지 않도록 정의.
2. 위와 같이 새로운 $q\_{\sigma}(x\_{t-1} \| x\_t, x\_0)$를 만들었으면 이것과 실제 모델의 학습 분포 $p\_{\theta}$와 같게 만들 때, DDPM의 손실 함수와 같은 목적 함수를 갖는지 확인한다.
3. 2번까지 완료 되었으면, 이제 1에서 도입한 $q\_{\sigma}(x\_{t-1} \| x\_t, x\_0)$를 추론에 사용한다. 모델은 DDPM과 같이 $\epsilon_t$를 예측하고 이를 $q\_{\sigma}(x\_{t-1} \| x\_t, x\_0)$식을 활용하여 $x\_{t-1}$를 구한다. 자세한 샘플링 알고리즘은 아래에 다시 설명.
### Non-markovian forward processes
DDPM에서 정의한 inference distribution을 변형한다. 
\begin{equation}
q\_{\sigma}(x\_{1:T} \| x\_0) = q\_{\sigma}(x\_T \| x\_0)\prod_{t=2}^{T}q\_{\sigma}(x\_{t-1} \| x\_t, x\_0)
\end{equation}

증명은 아래와 같다.
![](/assets/images/2022-12-03-DDIM/2.jpg)

이 때, DDPM에서 forward process $q(x_t \| x_{t-1}) = \mathcal{N}(x_t; \sqrt{\frac{\alpha_t}{\alpha_{t-1}}}x_{t-1}, (1 - \frac{\alpha_t}{\alpha_{t-1}})I)$라 정의하였고, $q(x_t \| x_0) = \mathcal{N}(x_t; \sqrt{\alpha_t}x_0, (1-\alpha_t)I$를 유도할 수 있다. DDPM에서의 beta notation을 본 DDIM 논문의 notation으로 대체함에 주의해야 한다. DDIM의 최종 목표는 DDPM의 훈련 방식을 건드리지 않고, DDPM으로 훈련된 모델의 샘플링 알고리즘에 deterministic을 더하는 것이다. 따라서 이러한 기저 성질들은 만족함과 동시해야한다. 

DDPM에서는 $q(x\_t \| x\_{t-1}, x\_0)$를 유도하기 위해 $q(x\_t \| x\_0)$와 베이지안 룰을 사용하였고, DDIM은 아래와 같이 정의하였다.

\begin{equation}
q\_{\sigma}(x\_{t-1} | x\_t, x\_0) = \mathcal{N}(\sqrt{\alpha_{t-1}}x\_0 + \sqrt{1-\alpha_{t-1} + \sigma_t^2}\cdot \frac{x\_t - \sqrt{\alpha_t}x\_0}{\sqrt{1-\alpha_t}}, \sigma_t^2I)
\end{equation}

이 식이 괜히 나온게 아니고, 앞에있는 forward process의 분포를 만족하면서 deterministic한 성질도 $\sigma$를 통해 주입할 수 있다. 추가적으로, appendix B의 Lemma를 보면 위의 $q\_{\sigma}(x_{t-1} \| x_t, x\_0)$가  $q(x_t \| x_0) = \mathcal{N}(x_t; \sqrt{\alpha_t}x_0, (1-\alpha_t)I$를 만족한다는 것도 귀납법으로 증명 되어있다. 

**그리고 정규분포의 합 공식에 의하여 parametrized 된 변수를 나누는 스킬을 사용한 것 같다. 아래 공식유도를 보자.**
![](/assets/images/2022-12-03-DDIM/3.jpg)

시그마가 0일 경우는 분산이 아예 없어지면서 같은 latent가 주어졌을 때 완전히 같은 이미지가 나오는 것이고, 시그마가 기존 DDPM의 분산과 같으면 DDPM과 같아지게 된다.

### Generative process and unified variational inference objective
먼저 위에서 정의한 $q\_{\sigma}(x\_{t-1} \| x\_t, x\_0)$를 활용하여 실제 샘플링 알고리즘을 코드와 함께 본다. 
샘플링 알고리즘을 요약하면,
1. $x\_t$와 t가 모델의 입력으로 주어진다.
2. 모델은 $t$에 해당하는 noise $\epsilon_t$를 출력한다.
3. $\epsilon_t$와 $q\_{\sigma}(x\_t \| x\_0)=\mathcal{N}(\sqrt{\alpha_t}x\_0, (1-\alpha_t)I)$를 활용하여 예측 $x\_0$, $\hat{x\_0}^t$를 구한다.
4. $q\_{\sigma}(x\_{t-1} \| x\_t, x\_0)$로 $x\_{t-1}$을 구한다.
5. 1~4를 n(50, 250, 1000)번 반복한다. 
이것을 코드로 나타내면 아래와 같다. 실제로 DDIM의 구현에서는 아래의 샘플링 코드만 바꾸면 나머지는 DDPM과 모두 같다. 아래 코드에서 n_sample_timesteps는 훈련에 사용한 1000이 아닌 더 작은 숫자일수 있고, eta는 논문의 eq. (16)의 $\eta$와 같다. 
```python
  @torch.no_grad()
  def ddim_sample_loop(self, shape, n_sample_timesteps, eta):
      t_lst = torch.linspace(-1, self.n_timesteps-1, steps=n_sample_timesteps+1)
      t_lst = list(reversed(t_lst.int().tolist()))
      t_pairs = list(zip(t_lst[:-1], t_lst[1:]))
      x = torch.randn(shape).cuda(self.args.local_rank)  # x_T
      pred_x_0 = None
      for t, t_1 in t_pairs:
          time = torch.full([x.shape[0], ], t, dtype=torch.long).cuda(x.get_device())
          x_self_cond = pred_x_0 if self.args.self_condition else None
          preds = self.model_prediction(x, time, x_self_cond)
          eps_theta = preds["pred_noise"]
          pred_x_0 = preds["pred_x_0"]
          if t_1 < 0:
              gene_img = pred_x_0
              break
          alpha_t = self.C.alphas_cumprod[t]  # DDIM이랑 DDPM의 notation은 약간 다름.
          alpha_t_1 = self.C.alphas_cumprod[t_1]
          
          sigma = eta * ((1-alpha_t_1) / (1-alpha_t)).sqrt() * (1 - alpha_t/alpha_t_1).sqrt()
          x_t_1 = alpha_t_1.sqrt() * pred_x_0 + (1-alpha_t_1-sigma**2).sqrt() * eps_theta + sigma*torch.randn_like(x)  # DDIM eq 12
          x = x_t_1
      return gene_img
```

이제 DDPM에서와 같이 $q\_{\sigma}(x\_{t-1} \| x\_t, x\_0)$와 $p\_{\theta}(x\_{t-1} \| x\_t)$를 맞추는 손실함수를 살펴보자. 논문의 eq. (11)에서와 같이 DDPM의 $q$가 $q\_{\sigma}$로 변한 것 이기 때문에 식의 형태는 거의 같다. 보이고자 하는 것은 결국 DDPM의 손실함수 $L$과 DDIM의 손실함수 J가 최적화 관점에서 같나인데, 이를 증명한 것이 theorem 1. 증명유도는 단순 수식 정리이기 때문에 쉽고, 증명 과정을 정리하면, 
1. 추론 알고리즘을 참고하여, $p\_{\theta}$가 $q\_{\sigma}$로 바뀔 수 있다. (최종적으로 두 분포를 같게 하기 때문.)
2. 두 분포의 KL divergence를 계산하면, 실제 이미지 $x\_0$과 t에서의 예측 이미지 $x\_0^t$의 거리를 최소화 하는것.
3. 두 이미지를 다시 noise관점으로 정리하면 결국 DDPM에서 제시한 noise끼리의 MSE와 같게 된다. 


# Experiments
실험에서 주목할 것은 sigma를 아래와 같이 설정한 것.

\begin{equation}
\sigma_t(\eta) = \eta \sqrt{\frac{1-\alpha_{t-1}}{1-\alpha_t}} \sqrt{1 - \frac{\alpha_t}{\alpha_{t-1}}}
\end{equation}
$\eta=1$이면 위의 식은 DDPM의 $\tilde{\beta_t}$와 같다. $\eta=0$이면 DDIM이다. $\eta$가 작아질수록 deterministic이 커지고, $\eta$클수록 DDPM과 같아진다. 

실험의 결론만 정리하면 아래와 같다.
1. 논문에서는 샘플링 횟수를 $dim(\tau)$라 표기했는데, 이 값이 작을 때 DDIM이 DDPM보다 월등히 성능이 좋았다. 즉, 더 빠른 추론이 가능하다. 
2. Interpolation이 좀 더 자연스럽다. 
3. Reconstruction 실험도 하였는데, 여기서도 error의 값이 0에 수렴한다. 즉 deterministic한 성질이 반영되어 있다. 

