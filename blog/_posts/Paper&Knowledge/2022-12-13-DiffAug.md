---
title: "[NeurIPS2020]Differentiable Augmentation for Data-Efficient GAN Training"
excerpt: "[NeurIPS2020]Differentiable Augmentation for Data-Efficient GAN Training"
categories:
  - Paper & Knowledge
  
tags:
  - GAN
 
published: True
toc: true
toc_sticky: true
toc_label: "On this page"
use_math: true
    
last_modified_at: 2022-12-13T15:04:00-05:00
---

* aug = augmentation
본 논문을 포스팅 하기 전에 정리한 것을 읽어보면 도움이 된다. 
1. GAN의 training dataset을 늘리기 위한 augmentation이 필요하다. 왜냐하면 GAN의 학습 불안정은 데이터셋의 양에도 관련이 있고, 일반적으로 GAN은 D가 학습 데이터를 외우는 오버피팅 때문에 학습이 잘 안되는 경향이 강하다.
2. 먼저 real 샘플을 augmentation한다. 이렇게 되면 발생하는 문제는 real data의 분포를 바꾸었기 때문에 실제 생성 데이터도 augmentation이 적용된 이미지가 나온다.
3. 다음으로는 D를 업데이트 하는 과정만 augmentation을 한다. 이 때 문제점은 D가 augmentation된 real과 gene를 잘 분류하지만 실제 gene를 분류하는 능력이 떨어진다. 이렇게 되면 G는 gradient가 흐르지 않는다. 왜냐하면 실제 gene (=G(z))를 분류할 수 없으므로 G가 생성한 이미지에 대한 loss가 없다.
4. 미분이 가능한 color, translation, cutout을 적용하였다. D와 G를 업데이트할 떄 모두 사용한다. 

Jun-Yan Zhu의 논문을 찾아보다가 발견한 논문. NVIDIA에서 발표한 StyleGAN2-ADA와 마찬가지로 GAN을 위한 augmentation을 제시한 논문이다. 이 논문은 내가 본 것 중에 가장 명확하고 약점이 없는 논문이다. 본 논문에서는 최종적인 diffaug를 제시하기 전에 2번의 insight를 얻는 실험을 진행하는데 이를 유심히 기억하자. 또한 코드도 쉽고 adaptive하므로 굳이 구현 없이도 쉽게 적용할 수 있다. 추후에 GAN이나 다른 생성에도 적용해보면 좋을 듯 하다. 

# Abstract & Introduction
GAN의 고질적인 문제점은 training unstability와 큰 training dataset를 필요로 하는 것이다. 특히, training dataset이 크면 학습도 안정적으로 되는 경우가 있기 때문에 큰 training dataset을 얻는것이 더욱 중요해진다. 이 논문에서는 classification과 같은 CNN모델이 aug를 필수적으로 사용하는데, GAN과 같은 생성 모델에서는 활용되지 않았던 이유를 분석하고, 해결책을 제시한다. 본 논문에서 주장하는 바에 따르면, GAN에서 문제는 Discriminator (D)에 보통 있다고 할 수 있는데, 학습이 잘 안되는 경우에는 학습이 불안정하고, 이 때 D가 학습 데이터를 외우기 떄문에 발생한다고 한다. 특히 D가 학습 데이터를 외우는 현상은 당연하게도 training dataset이 작으면 더욱 심해진다 == 오버피팅. 우리가 대표적으로 분류에서 이러한 학습데이터의 오버피팅을 막는 가장 직관적이면서 효과적인 방법으로 aug를 들 수 있다. 분류에서는 같이 학습 데이터를 aug한다 해도 미리 정해진 레이블은 변하지 않는다. 즉, 대부분의 경우 augmentation이 데이터의 본질을 바꾸지는 않는다. 이는 supervised 문제를 해결하기 위해서 그렇지만, 생성에서는 우리는 실제 존재하는 이미지를 생성해야 하기 떄문에 이렇게 직관적인 방법으로는 문제점이 발생한다. 이는 추후에 설명한다. 또한 본 논문에서 제시하는 augmentation적인 regularization은 기존 GAN의 학습 안정화를 돕는 spectral normalization과 독립적으로 GAN의 성능 향상을 이끌었다. 

# Method 
diffaug를 제시하기 전에 충분한 실패를 거쳐 합당한 방법론을 제시한다. 2가지의 실패 케이스를 설명하기 전에 GAN의 adversarial loss식을 적어둔다. 왜냐하면 D와 G의 update를 분리해서 설명하기 전에 notation으로 적어둘 필요가 있기 때문이다.

\begin{equation}
\mathcal{L}\_D = \mathbb{E}\_{x\sim p\_{data}(x)}[f\_D(-D(x))] + \mathbb{E}\_{z\sim p(z)}[f\_D(D(G(z)))]
\end{equation}

### Augment reals only.
GAN을 위한 augmentation에서 **가장 먼저 생각해 볼 수 있는것**은 내가 현재 갖고 있는 실제 데이터에 augmentation을 적용하는 것이다. 이 경우 훈련 식은 아래와 같다.

\begin{equation}
\mathcal{L}\_D = \mathbb{E}\_{x\sim p\_{data}(x)}[f\_D(-D(T(x)))] + \mathbb{E}\_{z\sim p(z)}[f\_D(D(G(z)))]
\end{equation}

실제 데이터 x에 대해서만 transformation이 적용되었다. 하지만 수식적이 아닌 직관적으로, 이렇게 훈련한다면 GAN은 마스킹 되거나 contrast가 변형된 이상한 훈련 데이터를 생성데이터를 만드려고 할 것이므로, 결과적으로는 훈련 데이터를 바꾸는 것이 된다. 따라서 이 실패에서 얻을 수 있는 결론은 **real데이터 뿐만 아니라 gene데이터에도 augmentation을 적용해야 한다는 것**이다.

### Augment D only.
위의 실험으로부터 real과 gene모두 augmentation을 적용해야 한다는 사실을 전제로, GAN의 학습 과정에서 주로 먼저 짚고가야할 D의 관점에서 생각할 수 있다. real과 gene모두 augmentation을 적용하고, classifier인 D가 오버피팅 되지 않도록 D에 대해서만 augmentation 적용한 이미지로 업데이트 시킬 수 있다. 수식은 아래와 같다.

\begin{equation}
\mathcal{L}\_D = \mathbb{E}\_{x\sim p\_{data}(x)}[f\_D(-D(T(x)))] + \mathbb{E}\_{z\sim p(z)}[f\_D(D(T(G(z))))]
\end{equation}

이렇게 되면 문제는 아래 그림에서 볼 수 있듯이, D가 aug가 적용된 real과 gene, 즉, $T(x)와 T(G(z))$만 잘 분류할 수 있게 된다는 것이다. 왜냐하면 D는 업데이트 동안 aug가 적용된 이미지를 분류할 수 있도록 훈련되는데, G의 업데이트식을 보면, D에게 G에서 생성한 이미지를 못맞추도록 훈련된다. 목표가 약간 어긋나있는 것을 볼 수 있다. 따라서 아래의 그림과 같은 실험을 할 수 있다. 

![](/assets/images/2022-12-13-DiggAug/1.PNG)

그림에서보면, D는 aug가 적용된 real & gene를 잘 분류하는 반면, 실제 생성이미지 G(z)는 잘 분류하지 못한다. 이 말은 G가 D를 이미 충분히 잘 속였기 때문에 G로 흐르는 gradient가 없다고 볼 수 있다. 따라서 이 방법도 훈련이 되지 않는다. 

### Differentiable Augmentation for GANs
위의 2방법론으로부터 두가지의 결론을 내릴 수 있다. 
1. augment real only => real에만 하면 완전히 분포가 달라지므로 fake에도 해야한다. 
2. augment D only => D에만 aug하면 G에서 생성된 이미지로 D를 너무 잘 속일 수 있다. G도 aug해야한다.

따라서 본 논문에서는 기존에 있던 세가지의 augmentation을 미분 가능하도록 코딩하여 훈련 프레임워크에 추가한다.
1 Translation : zero padding shift라고 보면 된다. 
2. Cutout : 이미지의 중간을 zero로 만든다.
3. Color : brightness와 contrast를 조절한다.

# Experiment 
실험은 BigGAN과 StyleGAN2를 사용하는데 일관적으로 다 성능이 잘 오른다. 실제 stylegan2에서는 ada라는 비슷한 논문을 공식 코드에 넣었다. 
