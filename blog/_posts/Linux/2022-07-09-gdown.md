---
title:  "리눅스 서버에서 구글 드라이브 파일 바로 다운로드"
excerpt: "리눅스 서버에서 구글 드라이브 파일 바로 다운로드"
categories:
  - Linux
  
tags:
  - Linux
 
published: True
toc: true
toc_sticky: true
toc_label: "On this page"
use_math: true
    
last_modified_at: 2022-07-09T15:33:00-05:00
---

INIT dataset을 다운받기 위해 4가지 도메인, sunny, cloudy, night, rainy를 다운 받으려고 한다. 하지만 이것들의 총 용량이 너무 크기 때문에 로컬에는 바로 다운로드 할 수가 없다.
결과적으로는 wget은 원인을 찾지 못했지만 rainy를 제외하고는 에러 파일 한개가 다운받아지고, gdown도 마찬가지로 rainy를 제외한 대용량 도메인들은 일일 다운로드 양을 초과했다는 문구가 나오면서 멈춘다. 
따라서 그냥 웹에서 클릭을 했으나 rainy같은 경우는 다이렉트로 서버에 다운 받을 수 있었다. 

rainy의 링크가 다음과 같다고 하자. https://drive.google.com/file/d/1IQS8ivuHnx9P5jtcGLVXnM5qU_iVhCvO/view
이거를 내 드라이브에 공유하여 링크를 새로 받아야 한다. 
1. 다른 사용자가 걸어둔 링크에 접속해서 오른쪽 위에 + 아이콘을 누르면 내 드라이브에 공유된다.
2. 내 드라이브로 가서 우클릭 후 링크 생성누르고 링크 복사.

현 예제에서는 링크가 다음과 같다. https://drive.google.com/file/d/1phcC_dUjT6YyimZU3TeFHWMsSChhJBjS/view?usp=sharing
d/과 /view 사이에 있는 1phcC_dUjT6YyimZU3TeFHWMsSChhJBjS 가 file id 이다. 이제 이것을 사용하여 리눅스에서 바로 다운받자. 
이렇게 링크를 얻었으면 fild id만 필요하다.
### wget을 이용한 방법
아래 명령어에서 {FILEID}에 위의 fild id를 넣고 (2 군데), {FILENAME}에 폴더 이름을 넣는다.  
wget --load-cookies ~/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILEID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id={FILEID}" -O {FILENAME} && rm -rf ~/cookies.txt

### gdown을 이용한 방법
위의 링크에서 fild id에 해당하는 부분을 다음과 같이 친다.
gdown --id 1phcC_dUjT6YyimZU3TeFHWMsSChhJBjS


